{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "import fiftyone.zoo as foz\n",
    "import fiftyone.brain as fob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |███████████████| 5149/5149 [15.3s elapsed, 0s remaining, 414.2 samples/s]      \n"
     ]
    }
   ],
   "source": [
    "# Create a new dataset and import the data in Pascal VOC format in one step\n",
    "dataset = fo.Dataset.from_dir(\n",
    "    dataset_dir='Images',\n",
    "    dataset_type=fo.types.VOCDetectionDataset,\n",
    "    name=\"cctv_gun_hackathon\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = foz.load_zoo_model(\"faster-rcnn-inception-resnet-atrous-v2-lowproposals-coco-tf\")\n",
    "resnet = foz.load_zoo_model(\"centernet-resnet101-v1-fpn-512-coco-tf2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.apply_model(model, label_field=\"predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = fo.load_dataset(\"cctv_gun_hackathon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800\"\n",
       "            src=\"http://localhost:5151/?notebook=True&subscription=db580fdd-8653-4257-b60d-4ec3bbb7d839\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x16b5d60bfa0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Launch the FiftyOne App to visualize your dataset\n",
    "session = fo.launch_app(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('id', <fiftyone.core.fields.ObjectIdField at 0x2d224f794e0>),\n",
       "             ('filepath', <fiftyone.core.fields.StringField at 0x2d224f79000>),\n",
       "             ('tags', <fiftyone.core.fields.ListField at 0x2d224f7e980>),\n",
       "             ('metadata',\n",
       "              <fiftyone.core.fields.EmbeddedDocumentField at 0x2d224f79600>),\n",
       "             ('created_at',\n",
       "              <fiftyone.core.fields.DateTimeField at 0x2d224f7fca0>),\n",
       "             ('last_modified_at',\n",
       "              <fiftyone.core.fields.DateTimeField at 0x2d224f78310>),\n",
       "             ('ground_truth',\n",
       "              <fiftyone.core.fields.EmbeddedDocumentField at 0x2d224f7ee00>)])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.get_field_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_model = foz.load_zoo_model(\"yolo11n-coco-torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone.brain as fob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:     cctv_gun_hackathon\n",
      "Media type:  image\n",
      "Num samples: 1534\n",
      "Sample fields:\n",
      "    id:               fiftyone.core.fields.ObjectIdField\n",
      "    filepath:         fiftyone.core.fields.StringField\n",
      "    tags:             fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)\n",
      "    metadata:         fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.ImageMetadata)\n",
      "    created_at:       fiftyone.core.fields.DateTimeField\n",
      "    last_modified_at: fiftyone.core.fields.DateTimeField\n",
      "    ground_truth:     fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
      "View stages:\n",
      "    1. SelectFields(field_names=['ground_truth'], meta_filter=None)\n",
      "    2. FilterLabels(field='ground_truth', filter={'label': 'Handgun'}, only_matches=True, trajectories=False)\n"
     ]
    }
   ],
   "source": [
    "view = dataset.select_fields(\"ground_truth\").filter_labels(\"ground_truth\", {\"label\": \"Handgun\"})\n",
    "print(view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:     cctv_gun_hackathon\n",
      "Media type:  image\n",
      "Num samples: 1\n",
      "Sample fields:\n",
      "    id:               fiftyone.core.fields.ObjectIdField\n",
      "    filepath:         fiftyone.core.fields.StringField\n",
      "    tags:             fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)\n",
      "    metadata:         fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.ImageMetadata)\n",
      "    created_at:       fiftyone.core.fields.DateTimeField\n",
      "    last_modified_at: fiftyone.core.fields.DateTimeField\n",
      "    ground_truth:     fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
      "View stages:\n",
      "    1. SelectFields(field_names=['ground_truth'], meta_filter=None)\n",
      "    2. Take(size=1, seed=None)\n"
     ]
    }
   ],
   "source": [
    "print(dataset.select_fields(\"ground_truth\").take(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing patch embeddings...\n",
      " 100% |███████████████| 5149/5149 [5.3m elapsed, 0s remaining, 13.0 samples/s]      \n",
      "Generating visualization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maria\\Documents\\GitHub\\hackathon-gun-detection\\.venv\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:1164: FutureWarning: 'n_iter' was renamed to 'max_iter' in version 1.5 and will be removed in 1.7.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 91 nearest neighbors...\n",
      "[t-SNE] Indexed 2721 samples in 0.007s...\n",
      "[t-SNE] Computed neighbors for 2721 samples in 1.292s...\n",
      "[t-SNE] Computed conditional probabilities for sample 1000 / 2721\n",
      "[t-SNE] Computed conditional probabilities for sample 2000 / 2721\n",
      "[t-SNE] Computed conditional probabilities for sample 2721 / 2721\n",
      "[t-SNE] Mean sigma: 1.291227\n",
      "[t-SNE] Computed conditional probabilities in 0.148s\n",
      "[t-SNE] Iteration 50: error = 79.8543396, gradient norm = 0.0019775 (50 iterations in 3.017s)\n",
      "[t-SNE] Iteration 100: error = 79.5112534, gradient norm = 0.0111010 (50 iterations in 1.849s)\n",
      "[t-SNE] Iteration 150: error = 78.7934341, gradient norm = 0.0024168 (50 iterations in 1.567s)\n",
      "[t-SNE] Iteration 200: error = 78.7911987, gradient norm = 0.0014051 (50 iterations in 1.242s)\n",
      "[t-SNE] Iteration 250: error = 78.7876892, gradient norm = 0.0033400 (50 iterations in 1.054s)\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 78.787689\n",
      "[t-SNE] Iteration 300: error = 2.3419640, gradient norm = 0.0076305 (50 iterations in 1.399s)\n",
      "[t-SNE] Iteration 350: error = 2.1092081, gradient norm = 0.0063756 (50 iterations in 1.092s)\n",
      "[t-SNE] Iteration 400: error = 2.0229850, gradient norm = 0.0049382 (50 iterations in 1.413s)\n",
      "[t-SNE] Iteration 450: error = 1.9819717, gradient norm = 0.0040772 (50 iterations in 1.866s)\n",
      "[t-SNE] Iteration 500: error = 1.9595892, gradient norm = 0.0032351 (50 iterations in 1.587s)\n",
      "[t-SNE] Iteration 550: error = 1.9457897, gradient norm = 0.0026537 (50 iterations in 1.579s)\n",
      "[t-SNE] Iteration 600: error = 1.9368695, gradient norm = 0.0022375 (50 iterations in 1.392s)\n",
      "[t-SNE] Iteration 650: error = 1.9311746, gradient norm = 0.0016774 (50 iterations in 1.345s)\n",
      "[t-SNE] Iteration 700: error = 1.9268739, gradient norm = 0.0016637 (50 iterations in 1.300s)\n",
      "[t-SNE] Iteration 750: error = 1.9233252, gradient norm = 0.0013178 (50 iterations in 1.264s)\n",
      "[t-SNE] Iteration 800: error = 1.9207448, gradient norm = 0.0011980 (50 iterations in 1.144s)\n",
      "[t-SNE] Iteration 850: error = 1.9185934, gradient norm = 0.0011069 (50 iterations in 1.136s)\n",
      "[t-SNE] Iteration 900: error = 1.9168177, gradient norm = 0.0009366 (50 iterations in 1.419s)\n",
      "[t-SNE] Iteration 950: error = 1.9155424, gradient norm = 0.0007775 (50 iterations in 1.122s)\n",
      "[t-SNE] Iteration 1000: error = 1.9144617, gradient norm = 0.0007037 (50 iterations in 1.365s)\n",
      "[t-SNE] KL divergence after 1000 iterations: 1.914462\n"
     ]
    }
   ],
   "source": [
    "gt_viz = fob.compute_visualization(dataset, patches_field=\"ground_truth\", brain_key=\"gt_viz1\", method=\"tsne\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800\"\n",
       "            src=\"http://localhost:5151/?notebook=True&subscription=09bac999-404a-4a0e-9bda-6a1deefec883\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1f8b840c6a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "session = fo.launch_app(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |███████████████| 5149/5149 [23.9m elapsed, 0s remaining, 4.6 samples/s]      \n"
     ]
    }
   ],
   "source": [
    "dataset.apply_model(\n",
    "    yolo_model,\n",
    "    label_field=\"predictions_yolo\",\n",
    "    confidence_thresh=0.5,  # optional confidence threshold for filtering predictions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'FiftyOneYOLODetectionModel' object has no attribute 'class_labels'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43myolo_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_labels\u001b[49m  \u001b[38;5;66;03m# get the class labels for the model\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'FiftyOneYOLODetectionModel' object has no attribute 'class_labels'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0% |---------------|   20/5149 [255.9ms elapsed, 1.1m remaining, 78.2 samples/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maria\\Documents\\GitHub\\hackathon-gun-detection\\.venv\\lib\\site-packages\\fiftyone\\utils\\yolo.py:1030: UserWarning: Ignoring object with label 'person' not in provided classes\n",
      "  warnings.warn(msg)\n",
      "c:\\Users\\maria\\Documents\\GitHub\\hackathon-gun-detection\\.venv\\lib\\site-packages\\fiftyone\\utils\\yolo.py:1030: UserWarning: Ignoring object with label 'tie' not in provided classes\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  12% |█\\-------------|  624/5149 [7.0s elapsed, 47.8s remaining, 168.1 samples/s]    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maria\\Documents\\GitHub\\hackathon-gun-detection\\.venv\\lib\\site-packages\\fiftyone\\utils\\yolo.py:1030: UserWarning: Ignoring object with label 'refrigerator' not in provided classes\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  18% |██\\------------|  922/5149 [9.1s elapsed, 38.8s remaining, 161.5 samples/s]    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maria\\Documents\\GitHub\\hackathon-gun-detection\\.venv\\lib\\site-packages\\fiftyone\\utils\\yolo.py:1030: UserWarning: Ignoring object with label 'skateboard' not in provided classes\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maria\\Documents\\GitHub\\hackathon-gun-detection\\.venv\\lib\\site-packages\\fiftyone\\utils\\yolo.py:1030: UserWarning: Ignoring object with label 'chair' not in provided classes\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  34% |█████\\---------| 1769/5149 [14.0s elapsed, 23.9s remaining, 185.0 samples/s]   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maria\\Documents\\GitHub\\hackathon-gun-detection\\.venv\\lib\\site-packages\\fiftyone\\utils\\yolo.py:1030: UserWarning: Ignoring object with label 'tv' not in provided classes\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  68% |██████████\\----| 3515/5149 [23.4s elapsed, 9.3s remaining, 192.4 samples/s]    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maria\\Documents\\GitHub\\hackathon-gun-detection\\.venv\\lib\\site-packages\\fiftyone\\utils\\yolo.py:1030: UserWarning: Ignoring object with label 'suitcase' not in provided classes\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |███████████████| 5149/5149 [43.5s elapsed, 0s remaining, 34.1 samples/s]       \n"
     ]
    }
   ],
   "source": [
    "dataset.export(\n",
    "    export_dir=\"yolo_predictions\",\n",
    "    dataset_type=fo.types.YOLOv5Dataset,\n",
    "    label_field=\"predictions_yolo\",  # specify the label field to export\n",
    "    overwrite=True,\n",
    "    classes=[\"Handgun\", \"Short_rifle\", \"Knife\", \"Person\"]  # specify the classes to include in the export, if needed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected person with confidence 0.86 at [0.48880500718951225, 0.21297980844974518, 0.0853787437081337, 0.36123624444007874]\n",
      "Detected person with confidence 0.84 at [0.3697461970150471, 0.1661607027053833, 0.06488790363073349, 0.380021333694458]\n",
      "Detected refrigerator with confidence 0.70 at [0.47455351054668427, 0.11471578478813171, 0.3089834749698639, 0.6675155162811279]\n",
      "Detected person with confidence 0.87 at [0.24307874590158463, 0.1225893497467041, 0.07297800481319427, 0.33450156450271606]\n",
      "Detected person with confidence 0.83 at [0.06334919854998589, 0.2903807461261749, 0.09277739375829697, 0.35758650302886963]\n"
     ]
    }
   ],
   "source": [
    "samples = dataset.take(5)\n",
    "for sample in samples:\n",
    "    pred = sample.get_field(\"predictions_yolo\")\n",
    "    if pred is None:\n",
    "        print(f\"No predictions found for sample {sample.id}\")\n",
    "        continue\n",
    "    for det in pred.detections:\n",
    "        print(f\"Detected {det.label} with confidence {det.confidence:.2f} at {det.bounding_box}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = dataset.compute_embeddings(model=yolo_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
